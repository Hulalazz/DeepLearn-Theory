# DeepLearn-Theory
Reading Group on Topics on theoretical, mathematical aspects of DL.
NYU, Fall 2016. Moderator: J. Bruna.

The purpose of this reading group is to define good open problems that relate 
Deep Learning models with aspects of statistics, applied maths and physics.
We are particularly interested in connections with statistical physics, optimization 
and harmonic analysis. Everyone is welcome.

##Information 
**Thursdays at 5pm**, Center for Data Science, NYU. 60 5th ave, 6th floor, **Room 606** 
##Logistics 
The goal is that each week a designated person(s) will present a selected paper, 
and possibly a bit of the mathematical context that is required to address it. 

##Tentative List of Topics:
  - Statistical Physics, Maximum Entropy 
  - Unsupervised Learning for Images and Time Series. 
  - Stochastic Optimization and Stability.
  - Gradient Descent, bassins of Attraction and Tensor Analysis.
  - Graph Theory, Invariance Groups and Convolutions.
  - Bandits.
  
##Tentative Agenda:
  - [9/22]: Optimization: Convex Review
    - [Theory of Convex Optimization](https://pdfs.semanticscholar.org/6505/a994da58234499dd7a8546bc07d9fd596518.pdf), by S. Bubeck.
    - [Large Scale Machine Learning and convex optimization](http://www.di.ens.fr/~fbach/#tutorials) by Francis Bach. 
  - [9/29]: Optimization: Non-Convex
    - [Learn Faster, Generalize Better](https://arxiv.org/abs/1509.01240) by Hardt, Recht and Singer.
  - [10/6]: Optimization: Non-Convex   
    - [Gradient Descent Conveges to Minimizers](https://pdfs.semanticscholar.org/9b8b/e6c3ebd7a79975067214e5eaea05d4ac2384.pdf) Lee et al.
    - [When are Nonconvex Problems Not Scary?](http://arxiv.org/pdf/1510.06096v2.pdf), by Sun et al.
  - [10/13]: Optimization: Neural Networks
    - [On the Quality of the Initial Bassin in overspecified Neural Networks](http://arxiv.org/abs/1511.04210), Safran and Shamir.
  - [10/20]: Optimization: Neural Networks
    - [Convexified Convolutional Neural Networks](http://arxiv.org/pdf/1609.01000v1.pdf), Zhang, P.Liang, M. Wainwright.
    - [Learning Half-Spaces and Neural Networks with Random Initializations](http://arxiv.org/pdf/1511.07948v1.pdf), Zhang et al.
  - [10/27]: Statistical Physics Basics
    - The Spin Glass Model.
  - [11/3]: Statistical Physics II
    - Large Deviation Principles, Micro-canonical ensembles, Entropy.
  - [11/10]: The Renormalization Group
    - [Renormalization Group: an introduction](http://www-math.unice.fr/~patras/CargeseConference/ACQFT09_JZinnJustin.pdf)
    - [K. Wilson Nobel Lecture](http://www.nobelprize.org/nobel_prizes/physics/laureates/1982/wilson-lecture.pdf)
    - [A mapping between RG and Deep Learning](http://arxiv.org/pdf/1410.3831v1.pdf)
  - [11/17]: Microcanonical Mixtures and CNNs.
    - Max-Entropy Gaussaniazation by Multiscale Scattering (J.B, S.M). 
  - [11/24]: Random Graphs I.   
    - The Stochastic Block Model
    - Community Dectection/Clustering.
    - Other Community models [Modularity and Community Structure in Networks](http://www.pnas.org/content/103/23/8577.full.pdf) 
  - [12/1]: Algorithms for Random Graphs
    - Spectral Methods
    - Graph Neural Networks
    - Semidefinite Programming. 
  - [12/1]: Deep Learning on Graphs
    - Geometric Deep Learning, by Bronstein, Bruna, Szlam, Lecun, Vandergyst.

##Pool of Papers/Books [please fill]
  - Les Houches Ellis Statistical Physics.
  - Gibbs Models and Sampling.
  - Renormalization Group (RG)
  - Learn faster generalize better
  - Draft Microcanonical Mixtures (JB)
  - Bassins of Attraction Shamir
  - Randomized PCA (Tygert et Al)
  - 




